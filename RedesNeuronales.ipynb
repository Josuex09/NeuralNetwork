{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este documento se explicará los pasos a seguir para implementar una red neuronal en Python, utilizando el método de propagación hacia atrás."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una Red Neuronal se puede modelar en 3 capas:\n",
    "* Capa de entrada: Esta capa se encuentran los datos de entrada.\n",
    "* Capa oculta: Es la encargada de procesar la entrada para obtener una predicción.\n",
    "* Capa de salida: Es la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "    \n",
    "    def __init__(self, input_layer,hidden_layer,output_layer):        \n",
    "        self.input_layer = input_layer\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self.output_layer = output_layer\n",
    "        \n",
    "        np.random.seed(853)\n",
    "        #Inicialmente los pesos de la capa oculta son escogidos aleatoriamente\n",
    "        #w1 es una matriz del tamano de entradas por el tamano de la capa oculta\n",
    "        #w2 es una matriz del tamano de la capa oculta por el tamano de la salida\n",
    "        self.w1 = np.random.randn(self.input_layer,self.hidden_layer)\n",
    "        self.w2 = np.random.randn(self.hidden_layer,self.output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagación hacia adelante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es el proceso para pasar de una entrada a una predicción por medio de los valores de la capa oculta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(self, x):\n",
    "    #Multiplicar las entradas por los valores de la primera sinapsis \n",
    "    self.z2 = np.dot(x, self.w1)\n",
    "    #El valor de aplicar la funcion de activacion a cada elemento de la matriz actual\n",
    "    self.a2 = self.activation_function(self.z2)\n",
    "    #Multiplicar las entradas por los valores de la segunda sinapsis\n",
    "    self.z3 = np.dot(self.a2, self.w2)\n",
    "    #El valor de aplicar la funcion de activacion a cada elemento de la matriz final\n",
    "    #Se obtiene la prediccion\n",
    "    goal = self.activation_function(self.z3) \n",
    "    return goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de activación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permite convertir cualquier valor numerico en una probabilidad (entre 0 y 1), de esta manera podremos saber cual es la probabilidad de que una muestra X pertenezca a una clase Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def activation_function(self, z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de costo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función de costo lo que realiza es evaluar la precisión existente entre los valores esperados y las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Permite saber que tan bien se comporta la red neuronal.\n",
    "def cost_function(self, x, y):\n",
    "    goal = self.forward_propagation(x)\n",
    "    j = 0.5*sum((y-goal)**2)\n",
    "    return j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagación hacia atrás"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es un proceso que basado en un costo obtiene la gradiente existente, la cual luego se utilizará para minimizar la función de costo, es decir, ir colina abajo (downhill). Para esto se utiliza la primera derivada de la función de costo, la misma define la pendiente de esta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def activation_function_d(self,z):\n",
    "    return np.exp(-z)/((1+np.exp(-z))**2)\n",
    "\n",
    "def backpropagation(self, x, y):\n",
    "    goal = self.forward_propagation(x)\n",
    "\n",
    "    delta3 = np.multiply(-(y-goal), self.activation_function_d(self.z3))\n",
    "    djdw2 = np.dot(self.a2.T, delta3)\n",
    "\n",
    "    delta2 = np.dot(delta3, self.w2.T)*self.activation_function_d(self.z2)\n",
    "    djdw1 = np.dot(x.T, delta2)  \n",
    "\n",
    "    return djdw1, djdw2\n",
    "\n",
    "def gradients(self, x, y):\n",
    "    djdw1, djdw2 = self.backpropagation(x, y)\n",
    "    return np.concatenate((djdw1.ravel(), djdw2.ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es el proceso por el cual, la red neuronal \"aprende\" para dar mejores predicciones por medio de un conjunto de datos dado. Para esto se utiliza el método del descenso por gradiente, el problema es que muchas veces dependiendo de la complejidad de la red, no se logra llegar a una buena solución. Para reducir el impacto de este problema, se utilizará una varinte de este método llamado BFGS(Broyden–Fletcher–Goldfarb–Shanno), debido a la estimación de la curvatura (segunda derivada) la cual permite utilizar esta información para dar mejores pasos hacia abajo de la colina (downhill). Dando así mejores resultados y de manera más eficiente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-40c10a718fdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m min_value = optimize.minimize(self.costFunctionWrapper, params, jac=True, method='BFGS', \n\u001b[0m\u001b[1;32m      3\u001b[0m                                  args=(X, y), options=options, callback=self.callbackF)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy import optimize\n",
    "min_value = optimize.minimize(self.costFunctionWrapper, params, jac=True, method='BFGS', \n",
    "                                 args=(X, y), options=options, callback=self.callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caso de estudio\n",
    "\n",
    "Creación de una Red Neuronal capaz de clasificar colores en formato de tupla RGB dentro de las categorías: Negro, Azul, Café,Gris, Verde, Naranja, Rojo, Violeta, Blanco y Amarillo.\n",
    "\n",
    "Para el entrenamiento se contaban con 646 registros, esto representa el 0,000038959 de la población.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "646./(255.*255.*255.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener la cantidad de nodos adecuados en la capa oculta, se evaluó  usar desde 4 hasta 70 y el mejor valor obtenido fue con 11, el cual da aproximadamente 4.512891 en la función de costo.\n",
    "\n",
    "Para obtener las clases más predominante de una imagen se realizó:\n",
    "* Cargar una imagen en formato RGB.\n",
    "* Evaluar cada pixel para clasificarlo en su respectiva clase.\n",
    "* Obtener la [Desviación estandar](https://es.wikipedia.org/wiki/Desviaci%C3%B3n_t%C3%ADpica)\n",
    "* Determinar las clases más predominantes, se toman los colores con mayor frecuencia y si su resta es menor a la desviación estándar se considera más de una clase predominante (un máximo de 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def round_closest(x):\n",
    "    return int(round(x,0))\n",
    "\n",
    "\n",
    "def get_colors_count(neural_network, image_path,class_array):  \n",
    "    im = Image.open(image_path)\n",
    "    rgb_im = im.convert('RGB')\n",
    "    width, height = im.size\n",
    "    color_counts = {}\n",
    "    \n",
    "    for i in range(0,width):\n",
    "        for j in range(0,height):\n",
    "            r,g,b = rgb_im.getpixel((i,j))\n",
    "            #Normalizar los valores\n",
    "            r = r/255.\n",
    "            g = g/255.\n",
    "            b = b/255.\n",
    "            index = round_closest(neural_network.forward_propagation([r,g,b])*9)\n",
    "            color = class_array[index]\n",
    "            if color in color_counts:\n",
    "                color_counts[color]+=1\n",
    "            else:\n",
    "                color_counts[color]= 1\n",
    "    \n",
    "    return color_counts\n",
    "        \n",
    "#Metodo que calcula la desviacion estandar de los colores\n",
    "def standard_deviation(color_counts):\n",
    "    average_value = average(color_counts)\n",
    "    acum = 0\n",
    "    for color in color_counts:\n",
    "        acum += (float(color_counts[color]) - average_value)**2\n",
    "    return math.sqrt(float(acum)/float(len(color_counts)))\n",
    "\n",
    "\n",
    "def average(color_counts):\n",
    "    acum = 0\n",
    "    for color in color_counts:\n",
    "        acum += color_counts[color]\n",
    "    \n",
    "    return float(acum) / float(len(color_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar la red neuronal creada, se utilizaron las siguientes imágenes:\n",
    "\n",
    "#### Prueba #1\n",
    "![Abstracta](abstract.jpg)\n",
    "\n",
    "Esta da los siguientes valores en cada clase:\n",
    "* Black: 88913\n",
    "* Red: 21532\n",
    "* Orange: 15838\n",
    "* Violet: 1263\n",
    "* Blue: 9135\n",
    "* Green: 8271\n",
    "* Grey: 7749\n",
    "* Brown: 3419\n",
    "* Yellow: 3053\n",
    "* White: 827\n",
    "\n",
    "Color Predominante: Black\n",
    "\n",
    "\n",
    "#### Prueba #2\n",
    "![Azul](blue.jpg)\n",
    "\n",
    "Esta da los siguientes valores en cada clase:\n",
    "* Blue: 145752\n",
    "* Brown: 51728\n",
    "* Black: 35635\n",
    "* Grey: 17115\n",
    "* Green: 5136\n",
    "* Orange: 446\n",
    "* Yellow: 67\n",
    "* Red: 47\n",
    "* White: 38\n",
    "* Violet: 36\n",
    "\n",
    "Colores Predominantes: Blue, Green\n",
    "\n",
    "\n",
    "#### Prueba #3\n",
    "![Verde](green.jpg)\n",
    "\n",
    "Esta da los siguientes valores en cada clase:\n",
    "* Green: 207595\n",
    "* Orange: 77228\n",
    "* White: 51411\n",
    "* Yellow: 49904\n",
    "* Red: 13192\n",
    "* Violet: 1629\n",
    "* Grey: 112\n",
    "* Black: 84\n",
    "* Blue: 76\n",
    "* Brown: 34\n",
    "\n",
    "Color Predominante: Green\n",
    "\n",
    "#### Prueba #4\n",
    "![Multicolor](multi.jpg)\n",
    "\n",
    "Esta da los siguientes valores en cada clase:\n",
    "* Red: 276515\n",
    "* Orange: 98671\n",
    "* Black: 78255\n",
    "* Blue: 75632\n",
    "* Green: 46859\n",
    "* Brown: 40614\n",
    "* Grey: 15496\n",
    "* Yellow: 11212\n",
    "* Violet: 4182\n",
    "* White: 3444\n",
    "\n",
    "Color Predominante: Orange\n",
    "\n",
    "#### Prueba #5\n",
    "![Violeta](images/violet.jpg)\n",
    "\n",
    "Esta da los siguientes valores en cada clase:\n",
    "* Violet: 156621\n",
    "* Red: 120250\n",
    "* Orange: 65165\n",
    "* Yellow: 523\n",
    "* White: 301\n",
    "* Black: 59\n",
    "* Blue: 29\n",
    "* Green: 25\n",
    "* Brown: 17\n",
    "* Grey: 10\n",
    "\n",
    "Colores Predominantes: Red, Violet\n",
    "\n",
    "#### Prueba #6\n",
    "![Atardecer](atardecer.jpg)\n",
    "\n",
    "Esta da los siguientes valores en cada clase:\n",
    "* Red: 30203\n",
    "* Orange: 152493\n",
    "* Black: 12777\n",
    "* Green: 977\n",
    "* Brown: 38719\n",
    "* Grey: 16459\n",
    "* Blue: 2214\n",
    "* Yellow: 1119\n",
    "* White: 195\n",
    "* Violet: 27966\n",
    "\n",
    "Colores Predominantes: Orange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
